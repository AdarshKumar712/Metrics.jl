<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>NLP Metrics · Metrics.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">Metrics.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../regression/">Regression Metrics</a></li><li><a class="tocitem" href="../classification/">Classification Metrics</a></li><li class="is-active"><a class="tocitem" href>NLP Metrics</a><ul class="internal"><li><a class="tocitem" href="#BLEU-Score-1"><span>BLEU Score</span></a></li><li><a class="tocitem" href="#Rouge-Score-1"><span>Rouge Score</span></a></li></ul></li><li><a class="tocitem" href="../cv/">CV Metrics</a></li><li><a class="tocitem" href="../rank/">Ranking Metrics</a></li><li><a class="tocitem" href="../utils/">Utils</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>NLP Metrics</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>NLP Metrics</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/AdarshKumar712/Metrics.jl/blob/master/docs/src/nlp.md#L" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Natural-Language-Procession-Metrics-1"><a class="docs-heading-anchor" href="#Natural-Language-Procession-Metrics-1">Natural Language Procession Metrics</a><a class="docs-heading-anchor-permalink" href="#Natural-Language-Procession-Metrics-1" title="Permalink"></a></h1><p>Once you have trained your NLP model, you need to evaluate the performance of the model. This package provide various metrics functions with which we can evaluate and assess the accuracy of the NLP model. However, their usefulness depends on the type of NLP problem you are working on.</p><h2 id="BLEU-Score-1"><a class="docs-heading-anchor" href="#BLEU-Score-1">BLEU Score</a><a class="docs-heading-anchor-permalink" href="#BLEU-Score-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="Metrics.bleu_score" href="#Metrics.bleu_score"><code>Metrics.bleu_score</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">bleu_score(reference_corpus, translation_corpus; max_order=4, smooth=false)</code></pre><p>Computes BLEU score of translated segments against one or more references. Returns the <code>BLEU score</code>, <code>n-gram precisions</code>, <code>brevity penalty</code>,  geometric mean of n-gram precisions, translation<em>length and  reference</em>length</p><p><strong>Arguments</strong></p><ul><li><code>reference_corpus</code>: list of lists of references for each translation. Each reference should be tokenized into a list of tokens.</li><li><code>translation_corpus</code>: list of translations to score. Each translation should be tokenized into a list of tokens.</li><li><code>max_order</code>: maximum n-gram order to use when computing BLEU score. </li><li><code>smooth=false</code>: whether or not to apply. Lin et al. 2004 smoothing.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/AdarshKumar712/Metrics.jl/blob/6cab3c598485b78c094613a680689445d4e511e1/src/NLP_Metrics/bleu.jl#LL32-L44">source</a></section></article><h2 id="Rouge-Score-1"><a class="docs-heading-anchor" href="#Rouge-Score-1">Rouge Score</a><a class="docs-heading-anchor-permalink" href="#Rouge-Score-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="Metrics.rouge_n" href="#Metrics.rouge_n"><code>Metrics.rouge_n</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">rouge_n(evaluated_sentences, reference_sentences; n=2)</code></pre><p>Computes ROUGE-N of two text collections of sentences. Returns f1, precision, recall for ROUGE-N.</p><p><strong>Arguments:</strong></p><ul><li><code>evaluated_sentences</code>: the sentences that have been picked by the summarizer</li><li><code>reference_sentences</code>: the sentences from the referene set</li><li><code>n</code>: size of ngram.  Defaults to 2.</li></ul><p>Source: (http://research.microsoft.com/en-us/um/people/cyl/download/   papers/rouge-working-note-v1.3.1.pdf)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/AdarshKumar712/Metrics.jl/blob/6cab3c598485b78c094613a680689445d4e511e1/src/NLP_Metrics/rouge.jl#LL111-L123">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Metrics.rouge_l_sentence_level" href="#Metrics.rouge_l_sentence_level"><code>Metrics.rouge_l_sentence_level</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">rouge_l_sentence_level(evaluated_sentences, reference_sentences)</code></pre><p>Computes ROUGE-L (sentence level) of two text collections of sentences.</p><p>Calculated according to:   R<em>lcs = LCS(X,Y)/m,   P</em>lcs = LCS(X,Y)/n,   F<em>lcs = ((1 + beta^2)*R</em>lcs*P<em>lcs) / (R</em>lcs + (beta^2) * P_lcs)</p><p>where:   X = reference summary   Y = Candidate summary   m = length of reference summary   n = length of candidate summary</p><p><strong>Argumnets:</strong></p><ul><li><code>evaluated_sentences</code>: the sentences that have been picked by the summarizer</li><li><code>reference_sentences</code>: the sentences from the referene set</li></ul><p>Source: (http://research.microsoft.com/en-us/um/people/cyl/download/papers/rouge-working-note-v1.3.1.pdf)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/AdarshKumar712/Metrics.jl/blob/6cab3c598485b78c094613a680689445d4e511e1/src/NLP_Metrics/rouge.jl#LL172-L193">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Metrics.rouge_l_summary_level" href="#Metrics.rouge_l_summary_level"><code>Metrics.rouge_l_summary_level</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">rouge_l_summary_level(evaluated_sentences, reference_sentences)</code></pre><p>Computes ROUGE-L (summary level) of two text collections of sentences.</p><p>Calculated according to:   R<em>lcs = SUM(1, u)[LCS&lt;union&gt;(r</em>i,C)]/m   P<em>lcs = SUM(1, u)[LCS&lt;union&gt;(r</em>i,C)]/n   F<em>lcs = ((1 + beta^2)*R</em>lcs*P<em>lcs) / (R</em>lcs + (beta^2) * P_lcs)</p><p>where:   SUM(i,u) = SUM from i through u   u = number of sentences in reference summary   C = Candidate summary made up of v sentences   m = number of words in reference summary   n = number of words in candidate summary</p><p><strong>Arguments:</strong></p><ul><li><code>evaluated_sentences</code>: the sentences that have been picked by the summarizer</li><li><code>reference_sentence</code>: the sentences in the reference summaries</li></ul><p>Source: (http://research.microsoft.com/en-us/um/people/cyl/download/papers/rouge-working-note-v1.3.1.pdf)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/AdarshKumar712/Metrics.jl/blob/6cab3c598485b78c094613a680689445d4e511e1/src/NLP_Metrics/rouge.jl#LL239-L262">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Metrics.rouge" href="#Metrics.rouge"><code>Metrics.rouge</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">rouge(hypotheses, references)</code></pre><p>Calculates average rouge scores for a list of hypotheses and references.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/AdarshKumar712/Metrics.jl/blob/6cab3c598485b78c094613a680689445d4e511e1/src/NLP_Metrics/rouge.jl#LL276-L280">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../classification/">« Classification Metrics</a><a class="docs-footer-nextpage" href="../cv/">CV Metrics »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Monday 25 May 2020 11:01">Monday 25 May 2020</span>. Using Julia version 1.0.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
